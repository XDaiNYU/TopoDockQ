# TopoDockQ: 

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

TopoDockQ is a topological deep learning model (TDL) that predicts protein-peptide binding quality using persistent combinatorial Laplacian-based features. The model leverages topological data analysis to extract meaningful features from protein-peptide interfaces and uses a neural network architecture to predict DockQ scores.

The YouTube installation & running guidance video can be found here: https://www.youtube.com/watch?v=IGOtribF4u4

An additional YouTube video demonstrating how to run the two Jupyter notebooks (01_tutorial_train.ipynb and 02_tutorial_inference.ipynb) as well as the scripts 03_extract_features_from_npy_to_csv.py and 04_inference_from_generated_csv.py is available here: https://youtu.be/i9tisUPIJcQ

![Figure](./image/combine_all.jpg)

**Co-first authored by:** Dr. Rui Wang <rw3594@nyu.edu>

**Corresponding Author:** Dr. Yingkai Zhang <yz22@nyu.edu>

## Data

### Protein-Peptide Interface Files
The protein-peptide interface PDB files can be downloaded from the [Zenodo repository](https://zenodo.org/record/15469415).

### Feature Extraction
The feature extraction algorithm used for generating TopoDockQ features is also available at: [TopoDockQ-Feature](https://github.com/wangru25/TopoDockQ-Feature)

### Training and Inference Data
Download the necessary feature and model files from the [Zenodo repository](https://zenodo.org/records/15469415):

- `processed_data.zip` (661.7 MB) contains:
  - `singlePPD_full_bins_features.csv`: Generated TopoDockQ features for model training, validation, and testing in the SinglePPD dataset.
  - `singlePPD_DockQ.csv`: Contains the full set of models in the SinglePPD dataset, including all 50 predictions per complex generated by AlphaFold2-Multimer.
  - `singlePPD_filtered_DockQ.csv`: A curated subset in which mutually highly similar models in the SinglePPD dataset, defined as pairs with DockQ â‰¥ 0.98 when compared against each other, have been removed from the training set. This filtering was applied by iteratively comparing each model against the other 49 models generated for the same target complex. Notably, only the training set is filtered using this criterion, while the validation and test sets remain unfiltered to better reflect real-world model selection scenarios
  
  **Installation:** Extract this zip file to `./data/processed_data/` folder

- `trained_model.zip` (66.9 MB) contains:
  - `best_model.pth`: Optimal pre-trained model for inference
  
  **Installation:** Extract this zip file to the `./models/` folder

## Requirements

- python=3.8.18
- numpy<=1.24.3
- pandas<=2.2.0
- scikit-learn=1.3.0
- gudhi=3.8.0
- pytorch>=2.0.0
- matplotlib>=3.5.0
- scipy>=1.9.0
- pillow>=8.0.0

## Installation

1. Clone the repository:
```bash
git clone https://github.com/XDaiNYU/TopoDockQ.git
cd TopoDockQ
```

2. Create and activate the conda environment:
```bash
conda env create -f environment.yaml
conda activate TopoDockQ
```

## Feature Generation

### Feature Extraction

To extract features from protein-peptide interface files:

```bash
python -m main --pdb_id PDBID --model_id MODELID --bins BINS --filtration FILTRATION --file_path FILEPATH --saving_path SAVINGPATH
```

**Parameters:**

- PDBID: A string, the Protein Data Bank ID. For example, 4k38
- MODELID: An int, the ID of the model. For example, 44.
- BINS: A string records bins' starting and ending points in a list format.
- FILTRATION: A string, records various distance-based filtration values. 
- FILEPATH: A string shows the directory of the protein-peptide data.
- SAVINGPATH: A string, indicates where the output feature file will be saved. 

**Example:**
```bash
python -m main --pdb_id 4k38 --model_id 44 --bins "[0, 2., 2.25, 2.5, 2.75, 3., 3.25, 3.5, 3.75, 4., 4.25, 4.5, 4.75, 5.]" --filtration "[0, 2., 2.25, 2.5, 2.75, 3., 3.25, 3.5, 3.75, 4., 4.25, 4.5, 4.75, 5.]" --file_path ./data/interface_files --saving_path ./feature
```

**Example with the same feature generation process as in the paper:**
```bash
python -m main --pdb_id 4k38 --model_id 44 --bins "[0, 2.  ,  2.25,  2.5 ,  2.75,  3.  ,  3.25,  3.5 ,  3.75,  4., 4.25,  4.5 ,  4.75,  5.  ,  5.25,  5.5 ,  5.75,  6.  ,  6.25, 6.5 ,  6.75,  7.  ,  7.25,  7.5 ,  7.75,  8.  ,  8.25,  8.5 , 8.75,  9.  ,  9.25,  9.5 ,  9.75, 10.]" --filtration "[2.  ,  2.25,  2.5 ,  2.75,  3.  ,  3.25,  3.5 ,  3.75,  4.  , 4.25,  4.5 ,  4.75,  5.  ,  5.25,  5.5 ,  5.75,  6.  ,  6.25, 6.5 ,  6.75,  7.  ,  7.25,  7.5 ,  7.75,  8.  ,  8.25,  8.5 , 8.75,  9.  ,  9.25,  9.5 ,  9.75, 10.]" --file_path ./data/interface_files --saving_path ./feature
```

**Output:** Features will be saved as `feature_4k38_ranked_44_sp_interface.npy` in the specified saving path.

**Transform the generated features from npy format to CSV format:**

```bash
python 03_extract_features_from_npy_to_csv.py --npy_file ./feature/feature_4k38_ranked_44_sp_interface.npy --output_file ./feature/example_features.csv        
```
**Output:** Features in CSV format will be saved as `example_features.csv ` in the specified saving path. Although the generated feature size is 2754, the valid features are 2646 after removal(can also be found at `./data/valid_columns.txt`). These features are set to 0 and can be safely removed, as described in the paper. 

## Model Training

**Prerequisites:** Before training, download the required data files:

1. Download `processed_data.zip` from the [Zenodo repository](https://zenodo.org/records/15469415)
2. Extract the zip file and place the contents in the `./data/processed_data/` folder
3. Ensure you have the following files in your data directory:
   - `singlePPD_DockQ.csv`
   - `singlePPD_filtered_DockQ`
   - `singlePPD_full_bins_features.csv`

**Recommended:** Use the Python script for training:

```bash
python 01_tutorial_train.py
```

**Note:** This is an example training script with 30 epochs. You can customize the number of epochs by modifying the `num_epochs` parameter in the script.

**For viewing outputs:** Jupyter notebook for interactive exploration and quick output viewing:

Install Jupyter Notebook** (if not already installed).
Follow the [official installation guide](https://jupyter.org/install) or simply run:
```bash
pip install notebook
```

```bash
jupyter notebook 01_tutorial_train.ipynb
```

The training process includes:
- Data preprocessing and feature engineering
- Model architecture configuration
- Training hyperparameters
- Model evaluation and validation
- Automatic model saving and checkpointing
- Meaningless features removel; the valid features are 2646 after removel(can also be find at `./data/valid_columns.txt`).

**Key Hyperparameters:**

- Input dimension: 2646
- Hidden layers: 2048 neurons each (4 layers)
- Learning rate: 0.0005
- Batch size: 512
- Dropout: 0.0

**Training Outputs:**

The training script generates the following files in the  `./model/` directory:

- `example_MLP_best_model.pth`: Model with best validation loss
- `example_MLP_best_pcc_model.pth`: Model with best validation PCC
- `example_MLP_30epoch.pth`: The last epoch model after training
- Training plots: RMSE and PCC curves displayed during training

### Model Inference

**Prerequisites:** Before running inference, ensure you have:

1. Downloaded `trained_model.zip` from the [Zenodo repository](https://zenodo.org/records/15469415), unzipped it, and placed the `best_model.pth` file in the `./models/` folder

**Recommended:** Use the Python script for inference:

```bash
python 02_tutorial_inference.py
```

**For viewing outputs:** Jupyter notebook for interactive exploration and quick output viewing:
Install Jupyter Notebook** (if not already installed).
Follow the [official installation guide](https://jupyter.org/install) or simply run:
```bash
pip install notebook
```

```bash
jupyter notebook 02_tutorial_inference.ipynb
```

**For inference on generated features in CSV format:** 
The CSV file can be generated with the `03_extract_features_from_npy_to_csv.py` script as described in the *Feature Generation* step.  
In this example script `python 04_inference_from_generated_csv.py`, the CSV file path is set as `df3_file='./feature/example_features.csv'`.  
You may need to change it if you're using a different working folder.  
You can also find `./example_inference_results.csv` as the output.

```bash
python 04_inference_from_generated_csv.py
```
> **Output** \
> ........\
> Extracting features and targets...  
> Standardizing features...  
> Using device: cpu  
> Loading model from ./models/best_model.pth...  
> Performing inference on single set...  
> [[0.15463054]]  # This is the prediction values p-DockQ.
> Inference completed successfully!


The inference process includes:
- Loading pre-trained models
- Feature preprocessing for inference
- Making predictions on validation and test data
- Model performance evaluation with metrics (RMSE, PCC)
- Saving results to CSV files

**Model Options:**

- Use the optimal model (`best_model.pth`) provided in the `trained_model.zip` in [Zenodo repository](https://zenodo.org/record/15469415)

**Inference Outputs:**

The inference script generates the following files in the project root directory:

- `val_inference_results.csv`: Validation set predictions with true vs predicted DockQ scores
- `test_inference_results.csv`: Test set predictions with true vs predicted DockQ scores
- `./example_inference_results.csv`: Output predicted DockQ scores from example with `04_inference_from_generated_csv.py` script.

Each CSV file contains:
- `True_DockQ`: Actual DockQ scores from the dataset
- `Predicted_DockQ (p-DockQ)`: Model predictions

The script also displays performance metrics:
- RMSE (Root Mean Square Error)
- PCC (Pearson Correlation Coefficient)

## Citation

If you use TopoDockQ in your research, please cite:

```bibtex
@article{dai2025topological,
  title={Topological Deep Learning for Enhancing Peptide-Protein Complex Prediction},
  author={Dai, Xuhang and Wang, Rui and Zhang, Yingkai},
  journal={in review},
  year={2025}
}
```

## Complex Interface PDB Files Generation:
- This step is flexible: you may use any molecular visualization or analysis software, such as PyMOL, ChimeraX, or scripting libraries like Biopython or ProDy, to generate interface structures.
- For convenience, we provide a ready-to-use script, extract_interface.py, located in the ./src/ directory. This script is based on ProDy, so please install [ProDy](https://github.com/prody/ProDy) before running it.

## Other Helpful References for Persistent Combinatorial Laplacians:
- R. Wang, R. Zhao, E. Ribando-Gros, J. Chen, Y. Tong, and G.-W. Wei. [HERMES: Persistent spectral graph software](https://www.aimsciences.org/article/doi/10.3934/fods.2021006), _Foundations of Data Science_, 3(1), 67, 2021.
- R. Wang, D. D. Nguyen, and G.-W. Wei. [Persistent spectral graph](https://users.math.msu.edu/users/weig/paper/p243.pdf), _International Journal for Numerical Methods in Biomedical Engineering_, 36(9), page e3376, 2020.

## Contact

For feature generation questions and support, please contact:
- Dr. Rui Wang: <rw3594@nyu.edu>

For model training questions and support, please contact:
- Mr. Xuhang Dai: <xd638@nyu.edu>
- Dr. Rui Wang: <rw3594@nyu.edu>
